import src.common.GlobalSetting as gl
from ollama import Client
from langchain_community.chat_models import ChatOllama
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import initialize_agent, AgentType
from src.tools.tavily_client import tavily_client
from dotenv import load_dotenv

load_dotenv()

llm_client = Client(host="http://127.0.0.1:11434")
model_name = gl.MODEL_NAME
llm = ChatOllama(model="llama3", base_url="http://127.0.0.1:11434")
search_tool = TavilySearchResults(max_results=2)

# Function-style Agent (ë¹ ë¥¸ íˆ´ ì²˜ë¦¬)
agent = initialize_agent(
    tools=[search_tool],
    llm=llm,
    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True,
    handle_parsing_errors=True,
)


def run_tavily_and_get_urls(query: str, max_results: int = 3):
    try:
        res = tavily_client.search(query, max_results=max_results)
        urls = [item["url"] for item in res.get("results", []) if "url" in item]
        return urls
    except Exception as e:
        print("[Tavily Error]", e)
        return []


def stream_chat(mem, messages):
    """
    - Ollamaë¡œ ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€
    - í•„ìš”í•˜ë©´ ì¤‘ê°„ì— Tavily ê²€ìƒ‰ ê²°ê³¼ë¥¼ Observationì²˜ëŸ¼ ë¶™ì—¬ì„œ ë§ˆë¬´ë¦¬
    """
    user_text = messages[-1]["content"]

    # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ê°„ ê²°ê³¼ ëª¨ìœ¼ê¸°
    chunks = []
    for chunk in llm_client.chat(
        model=model_name, messages=messages, stream=True, options={"num_predict": 1024}
    ):
        if isinstance(chunk, tuple):
            chunk = chunk[0]
        if "message" in chunk and "content" in chunk["message"]:
            piece = chunk["message"]["content"]
            piece = (
                piece.replace("<|system|>", "")
                .replace("<|user|>", "")
                .replace("<|assistant|>", "")
            )
            chunks.append(piece)
            yield piece  # ì‚¬ìš©ìì—ê²Œ ì‹¤ì‹œê°„ ì „ì†¡

    assistant_text = "".join(chunks).strip()

    # ğŸ”‘ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì´ë©´ Tavily ì‹¤í–‰
    if any(
        keyword in user_text
        for keyword in [
            "ê²€ìƒ‰",
            "ë§›ì§‘",
            "ìœ„ì¹˜",
            "ì–´ë””",
            "ìƒµ",
            "shop",
            "store",
            "restaurant",
            "news",
        ]
    ):
        urls = run_tavily_and_get_urls(user_text, max_results=3)
        if urls:
            obs_text = "\n\nğŸ” ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ë§í¬:\n" + "\n".join(urls)
            assistant_text += obs_text
            yield obs_text  # URLë„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì´ì–´ ë¶™ì´ê¸°

    # ë©”ëª¨ë¦¬ì— ìµœì¢… ë‹µë³€ ì €ì¥
    mem.add_assistant(assistant_text)
