import src.common.GlobalSetting as gl
from ollama import Client
from langchain_community.chat_models import ChatOllama
from src.tools.tavily_client import run_tavily_and_get_urls, tavily_chat
from dotenv import load_dotenv
import os 
from openai import OpenAI
import json
import base64


load_dotenv()

llm_client = Client(host="http://127.0.0.1:11434")
model_name = gl.MODEL_NAME
llm = ChatOllama(model="llama3", base_url="http://127.0.0.1:11434")


api_key = os.getenv("OPENAI_API_KEY")
gpt = OpenAI(api_key=api_key)



def main_chat(mem, messages):
    user_text = messages[-1]["content"]

    chunks = []
    for chunk in llm_client.chat(
        model=model_name, messages=messages, stream=True, options={"num_predict": 1024}
    ):
        if isinstance(chunk, tuple):
            chunk = chunk[0]
        if "message" in chunk and "content" in chunk["message"]:
            piece = chunk["message"]["content"]

            chunks.append(piece)
            yield piece 
            

    assistant_text = "".join(chunks).strip()

    # ğŸ”‘ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì´ë©´ Tavily ì‹¤í–‰
    if any(
        keyword in user_text
        for keyword in [
            "ê²€ìƒ‰",
            "ë§›ì§‘",
            "ìœ„ì¹˜",
            "ì–´ë””",
            "ìƒµ",
            "shop",
            "store",
            "restaurant",
            "news",
        ]
    ):
        urls = run_tavily_and_get_urls(user_text, max_results=1)
        if urls:
            obs_text = "\n\nğŸ” ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ë§í¬:\n" + "\n".join(urls)
            assistant_text += obs_text
            yield obs_text  # URLë„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì´ì–´ ë¶™ì´ê¸°
    
    if any(
        keyword in user_text
        for keyword in [
            "ì¼€ë°í—Œ",
            "ì¼€ì´íŒë°ëª¬í—Œí„°ìŠ¤",
            "ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤",
            "êµ¿ì¦ˆ",
            "goods",
            'merchandise'
            "ìƒí’ˆ",
            "products",
            "items",
            "ê¸°ë…í’ˆ",
            "souvenir"
        ]
    ):
        goods_images = [
            "goods/dufy.png",
            "goods/hunt.png",
            "goods/sin.png",
            "goods/ts.png",
        ]
        
        yield "\n" + json.dumps({"type": "images", "content": goods_images}) + "\n" # chunk ë‹¨ìœ„ë¡œ ë³´ë‚´ì§€ ì•Šê³  í•œì¤„ë¡œ ë³´ë‚´ë„ë¡ ì²˜ë¦¬
        
    assistant_text.replace("<|system|>", "").replace("<|user|>", "").replace("<|assistant|>", "")
    mem.add_assistant(assistant_text)


# GPT Router: íˆ´ í˜¸ì¶œ ì—¬ë¶€ íŒë‹¨ ---
def routing_with_gpt(user_text: str) -> str:
    """
    GPT APIë¥¼ ì‚¬ìš©í•´ì„œ 'chat' or 'search' íŒë‹¨
    """
    system_prompt = """You are a router agent.
Decide if the user question needs real-world search (e.g. restaurants, locations, news).
Respond ONLY with one word: 'chat' or 'search'."""

    completion = gpt.chat.completions.create(
        model="gpt-4o-mini",  
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_text},
        ],
        max_tokens=2,
    )
    return completion.choices[0].message.content.strip().lower()


def chat(mem, messages, image):
    
    if image:
        print('exist image')
        # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ì‚¬ìš©ì ì±„íŒ… ìì²´ë¥¼ '{image_kind}ê°€ ë­ì•¼ë¡œ ë°”ê¿”ì„œ ë¯¿ìŒì— ì§ˆì˜'
        image_name = infer_image_name(messages, image)
        messages = f'{image_name}ì— ëŒ€í•œ ì •ë³´ ì•Œë ¤ì¤˜'
        
    user_text = messages[-1]["content"]
    route = routing_with_gpt(user_text)
    print(f"[Router Decision] {route}")
    
    if route == "chat":
        for token in main_chat(mem, messages):
            yield token

    elif route == "search":
        obs_text = tavily_chat(user_text, max_results=2)
        messages.append({
            "role": "system",
            "content": f"ğŸ” Tavily ê²€ìƒ‰ ê²°ê³¼:\n{obs_text}\n\nìœ„ ë‚´ìš©ì„ ë°˜ì˜í•´ì„œ ë‹µë³€ì„ ë³´ê°•í•˜ì„¸ìš”."
        })
        for token in main_chat(mem, messages):
            yield token

    else:
        # fallback: ê·¸ëƒ¥ chat
        for token in main_chat(mem, messages):
            yield token

def infer_image_name(user_text, image):
    
    messages = [
        {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì  ì´ë¯¸ì§€ë¥¼ ë³´ë©´ ì¥ì†Œ/ë¬¼ê±´ ì´ë¦„ì„ ì •í™•í•˜ê²Œ íŒë‹¨ í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ ì „ë¬¸ê°€ì•¼"},
        {"role": "user", "content": "ì‘ë‹µì€ ê°„ë‹¨í•˜ê²Œ í•œ ë‹¨ì–´ë¡œ í•´ì¤˜ ì˜ˆë¥¼ ë“¤ìë©´ ë‹¤ìŒê³¼ ê°™ì•„ 'ìš”ì¿ ë¥´íŠ¸ íŒë§¤ì°¨', 'ê²½ë³µê¶, 'ë‚¨ì‚°'"}
    ]

    # í…ìŠ¤íŠ¸ ì¶”ê°€
    messages[1]["content"].append({
        "type": "text",
        "text": user_text
    })

    # ì´ë¯¸ì§€ ì¶”ê°€
    if image is not None:
        base64_image = base64.b64encode(image.read()).decode("utf-8")
        
        messages[1]["content"].append({
            "type": "image_url",
            "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
        })

    # LLM í˜¸ì¶œ
    response = gpt.chat.completions.create(
        model="gpt-5",
        messages=messages,
        temperature=0.0,
    )

    return response.choices[0].message["content"]